# ğŸ· Wine Classifier - ClassificaÃ§Ã£o de Vinhos com Aprendizado de MÃ¡quina

Este projeto aplica algoritmos de **aprendizado supervisionado** no clÃ¡ssico conjunto de dados **Wine Dataset**, disponÃ­vel no `sklearn.datasets`. O objetivo Ã© classificar vinhos com base em atributos fÃ­sico-quÃ­micos e avaliar o desempenho dos modelos **Naive Bayes** e **Random Forest**.

---

## ğŸ“ Sobre o Dataset

O **Wine Dataset** contÃ©m 178 amostras de vinhos, divididas em trÃªs classes (0, 1 e 2), correspondentes a diferentes cultivares da uva.

Cada amostra possui 13 atributos contÃ­nuos:

- `alcohol`, `malic_acid`, `ash`, `alcalinity_of_ash`, `magnesium`, `total_phenols`, `flavanoids`, `nonflavanoid_phenols`, `proanthocyanins`, `color_intensity`, `hue`, `od280/od315_of_diluted_wines`, `proline`.

---

## ğŸ§ª Metodologia

### ğŸ“Š PrÃ©-processamento

- **PadronizaÃ§Ã£o** dos dados com `StandardScaler()`
- DivisÃ£o em **conjunto de treino e teste** (80% / 20%)
- VisualizaÃ§Ã£o de padrÃµes com **PCA** e **grÃ¡ficos paralelos**

### ğŸ” Modelos Aplicados

#### ğŸ§  1. Naive Bayes

Algoritmo probabilÃ­stico que assume independÃªncia entre os atributos.

A prediÃ§Ã£o do Naive Bayes considera a classe com maior probabilidade conjunta:

P(C_k | x) âˆ P(C_k) * Î  P(x_i | C_k)

No caso Gaussiano:

P(x_i | C_k) = (1 / sqrt(2Ï€ÏƒÂ²)) * exp( - (x - Î¼)Â² / 2ÏƒÂ² )

#### ğŸŒ² 2. Random Forest

Ensemble de Ã¡rvores de decisÃ£o que reduz overfitting por meio da aleatoriedade na seleÃ§Ã£o de atributos e amostras.

HiperparÃ¢metros otimizados com **GridSearchCV**, testando:
- `max_depth` de 9 a 19
- `min_samples_split` de 2 a 9

---

## ğŸ“ˆ Resultados

### ğŸ” MÃ©tricas de AvaliaÃ§Ã£o

| Modelo         | AcurÃ¡cia | F1-score (macro) | Classe 0 | Classe 1 | Classe 2 |
|----------------|----------|------------------|----------|----------|----------|
| Naive Bayes    | **97%**  | 0.97             | 0.96     | 0.96     | 0.99     |
| Random Forest  | 96%      | 0.96             | 0.95     | 0.95     | 0.99     |

### ğŸ§¾ ClassificaÃ§Ã£o Naive Bayes

          precision    recall  f1-score   support
       0       0.95      0.97      0.96        40
       1       0.98      0.94      0.96        50
       2       0.97      1.00      0.99        34

### ğŸŒ² ClassificaÃ§Ã£o Random Forest (ajustada)

          precision    recall  f1-score   support
       0       0.97      0.93      0.95        40
       1       0.94      0.96      0.95        50
       2       0.97      1.00      0.99        34

---

## ğŸ“Œ ConclusÃµes

- Ambos os modelos apresentaram Ã³timo desempenho, com destaque para o **Naive Bayes** em termos de acurÃ¡cia global.
- O **Random Forest** teve vantagem em robustez e permite maior customizaÃ§Ã£o via tuning de hiperparÃ¢metros.
- O projeto ilustra como diferentes abordagens podem ser comparadas com base em **mÃ©tricas objetivas** e anÃ¡lises interpretÃ¡veis.

---

## âœï¸ Autor

Fernando âœ¨
ğŸ“š Bacharel em FÃ­sica | TÃ©cnico em EletrotÃ©cnica | CiÃªncia de Dados



